{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идентификация марковских моделей с помощью анализа последовательностей, по которым генерируются стохастические матрицы  \n",
    "\n",
    "Имеем следующие классы стохастических матриц:  \n",
    "\n",
    "1) Положительные  \n",
    "2) Дважды стохастические  \n",
    "3) С локальными вероятностными переходами  \n",
    "4) Квазитреугольные (верхние и нижние)  \n",
    "5) Блочно-сообщающиеся (правые и левые)  \n",
    "6) Разреженные с энтропией, равной 0,2; 0,4; 0,6  \n",
    "\n",
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.writer.excel import save_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantecon as qe\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from pycaret.regression import *\n",
    "from pycaret.classification import *\n",
    "from pycaret.clustering import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from matplotlib import pyplot as plt   \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод генерации матриц по последовательностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(transitions):\n",
    "    n = 1 + max(transitions)\n",
    "    M = [[0]*n for _ in range(n)]\n",
    "    \n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i][j] += 1\n",
    "        \n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем по одной матрице из каждого класса, генерируем новые матрицы и новые последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сюда вставляем по додной матрице из каждого класса\n",
    "matrix = np.array([\n",
    "    [0.000, 0.000, 0.641, 0.147, 0.212],\n",
    "    [0.000, 0.000, 0.196, 0.484, 0.320],\n",
    "    [0.000, 0.000, 0.017, 0.385, 0.598],\n",
    "    [0.544, 0.456, 0.000, 0.000, 0.000],\n",
    "    [0.499, 0.501, 0.000, 0.000, 0.000]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(100, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем массивы ответов и словарь частот встречаемости значений разности "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем частоты стречаемых значений разности между первым и вторым элементом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения поля target: P положит(резк) - 0, Бп - 1, Р положит(плав) - 2, Д - 3, ЛП - 4, Н_20 - 5, Н_40 - 6, Н_60 - 7, Тв - 8, Тн - 9, Бл - 10. Собираем все данные в xlsx файл, меняя параметры c1, с2, с3 для записи в ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = 1001\n",
    "c2 = 7001\n",
    "c3 = 1002\n",
    "\n",
    "wb = openpyxl.load_workbook('Sequence_properties.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Matrix')\n",
    "row = c2   \n",
    "column = 1\n",
    "for mat in list_m:\n",
    "    for ar in mat:\n",
    "        for el in ar:\n",
    "            ws2.cell(column=column, row=row).value = el\n",
    "            column = column + 1\n",
    "        row = row + 1\n",
    "        column = 1\n",
    "    row = row + 2 \n",
    "\n",
    "ws3 = wb.get_sheet_by_name('Properties')\n",
    "row = c3   \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws3.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, 'Sequence_properties.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   -4  -3  -2  -1   0  1  2  3  4  target\n",
       "0   3   4   0   1  83  1  0  3  4       0\n",
       "1   2   6   1   1  78  1  1  6  3       0\n",
       "2   5   3   0   2  79  1  0  2  7       0\n",
       "3   4   4   0   1  80  1  0  4  5       0\n",
       "4   4   6   0   2  74  2  0  6  5       0\n",
       "5   7   2   1   3  72  3  0  4  7       0\n",
       "6   4   4   0   2  77  3  0  5  4       0\n",
       "7   4   6   0   0  77  1  0  7  4       0\n",
       "8   4   6   0   0  78  0  0  6  5       0\n",
       "9   3   7   0   1  76  1  0  7  4       0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Sequence_properties.xlsx\", \"Properties\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По опыту работы с параметрами, вычисляемыми по матрицам, строим модели многоклассовой классификации для определения, к какому классу относятся полученные значения, вычисленные по последовательностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1)\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       0.86      0.97      0.91        31\n",
      "           3       1.00      0.94      0.97        35\n",
      "           4       1.00      1.00      1.00        28\n",
      "           5       0.97      0.92      0.94        37\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        29\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.98       330\n",
      "   macro avg       0.98      0.98      0.98       330\n",
      "weighted avg       0.98      0.98      0.98       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       0.93      0.84      0.88        31\n",
      "           3       0.88      1.00      0.93        35\n",
      "           4       1.00      1.00      1.00        28\n",
      "           5       0.97      0.95      0.96        37\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.97      1.00      0.98        29\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.97       330\n",
      "   macro avg       0.98      0.97      0.98       330\n",
      "weighted avg       0.97      0.97      0.97       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_proba = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, Y_train).predict(X_test)\n",
    "print(classification_report(Y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       0.90      0.87      0.89        31\n",
      "           3       0.97      1.00      0.99        35\n",
      "           4       1.00      1.00      1.00        28\n",
      "           5       0.92      0.92      0.92        37\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        29\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.98       330\n",
      "   macro avg       0.98      0.98      0.98       330\n",
      "weighted avg       0.98      0.98      0.98       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_proba = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X_train, Y_train).predict(X_test)\n",
    "print(classification_report(Y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        33\n",
      "           1       1.00      0.96      0.98        25\n",
      "           2       0.70      0.74      0.72        31\n",
      "           3       0.90      0.80      0.85        35\n",
      "           4       0.97      1.00      0.98        28\n",
      "           5       0.97      0.84      0.90        37\n",
      "           6       0.93      0.89      0.91        28\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.76      1.00      0.87        29\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       0.88      1.00      0.94        23\n",
      "\n",
      "    accuracy                           0.91       330\n",
      "   macro avg       0.92      0.92      0.92       330\n",
      "weighted avg       0.92      0.91      0.91       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_proba = OutputCodeClassifier(LinearSVC(random_state=0), code_size=2, random_state=0).fit(X_train, Y_train).predict(X_test)\n",
    "print(classification_report(Y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(9))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            -4        -3        -2        -1         0      1         2  \\\n",
       "0     0.157895  0.133333  0.000000  0.027027  0.943182  0.025  0.000000   \n",
       "1     0.105263  0.200000  0.028571  0.027027  0.886364  0.025  0.022222   \n",
       "2     0.263158  0.100000  0.000000  0.054054  0.897727  0.025  0.000000   \n",
       "3     0.210526  0.133333  0.000000  0.027027  0.909091  0.025  0.000000   \n",
       "4     0.210526  0.200000  0.000000  0.054054  0.840909  0.050  0.000000   \n",
       "...        ...       ...       ...       ...       ...    ...       ...   \n",
       "1095  0.421053  0.700000  0.314286  0.000000  0.000000  0.250  0.888889   \n",
       "1096  0.473684  0.766667  0.257143  0.000000  0.000000  0.300  0.711111   \n",
       "1097  0.368421  0.633333  0.428571  0.000000  0.000000  0.350  0.622222   \n",
       "1098  0.526316  0.733333  0.314286  0.000000  0.000000  0.250  0.622222   \n",
       "1099  0.473684  0.733333  0.257143  0.000000  0.011364  0.225  0.866667   \n",
       "\n",
       "             3         4  \n",
       "0     0.157895  0.129032  \n",
       "1     0.315789  0.096774  \n",
       "2     0.105263  0.225806  \n",
       "3     0.210526  0.161290  \n",
       "4     0.315789  0.161290  \n",
       "...        ...       ...  \n",
       "1095  0.368421  0.064516  \n",
       "1096  0.421053  0.193548  \n",
       "1097  0.789474  0.032258  \n",
       "1098  0.526316  0.258065  \n",
       "1099  0.315789  0.129032  \n",
       "\n",
       "[1100 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_of_values = {}\n",
    "count = len(X.columns.tolist())\n",
    "\n",
    "for i in range(0, count):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(np.array(X.iloc[:,i]).reshape(-1, 1))\n",
    "    scaled_data = scaled_data.reshape(len(scaled_data))\n",
    "    d_of_values[data.columns.tolist()[i]] = scaled_data\n",
    "    \n",
    "x = pd.DataFrame(d_of_values)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, dummy_y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 0s 984us/step - loss: 2.3214 - accuracy: 0.1636\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 2.1817 - accuracy: 0.3701\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 802us/step - loss: 2.0494 - accuracy: 0.4896\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 768us/step - loss: 1.9175 - accuracy: 0.4818\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 1.7899 - accuracy: 0.4701\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 1.5910 - accuracy: 0.4701\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 851us/step - loss: 1.3953 - accuracy: 0.4701\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 993us/step - loss: 1.1339 - accuracy: 0.6390\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 775us/step - loss: 0.9632 - accuracy: 0.6571\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.9006 - accuracy: 0.6974\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.8842 - accuracy: 0.7338\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 823us/step - loss: 0.7999 - accuracy: 0.7403\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.7574 - accuracy: 0.7506\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.6872 - accuracy: 0.7896\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.7922\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.6131 - accuracy: 0.7987\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 793us/step - loss: 0.6697 - accuracy: 0.7974\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 942us/step - loss: 0.5644 - accuracy: 0.7987\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 830us/step - loss: 0.5997 - accuracy: 0.8117\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.5526 - accuracy: 0.7883\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.5392 - accuracy: 0.7974\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 846us/step - loss: 0.5233 - accuracy: 0.8260\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.4979 - accuracy: 0.8338\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.4955 - accuracy: 0.8351\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.4886 - accuracy: 0.8325\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.4845 - accuracy: 0.8481\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.4289 - accuracy: 0.8636\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.4512 - accuracy: 0.8455\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 785us/step - loss: 0.4296 - accuracy: 0.8584\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.4494 - accuracy: 0.8792\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 893us/step - loss: 0.4579 - accuracy: 0.8623\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.4123 - accuracy: 0.8688\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.3796 - accuracy: 0.8857\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 898us/step - loss: 0.3600 - accuracy: 0.8857\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 814us/step - loss: 0.4093 - accuracy: 0.8688\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.3655 - accuracy: 0.8831\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.3968 - accuracy: 0.8675\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.3917 - accuracy: 0.8818\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 811us/step - loss: 0.3687 - accuracy: 0.8818\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 833us/step - loss: 0.3572 - accuracy: 0.8922\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.3589 - accuracy: 0.8779\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 810us/step - loss: 0.3281 - accuracy: 0.8948\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.3360 - accuracy: 0.8870\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 818us/step - loss: 0.3624 - accuracy: 0.8597\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.3480 - accuracy: 0.8779\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 876us/step - loss: 0.3466 - accuracy: 0.8805\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 868us/step - loss: 0.3209 - accuracy: 0.8844\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.3676 - accuracy: 0.8701\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.3742 - accuracy: 0.8623\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8831\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 809us/step - loss: 0.3215 - accuracy: 0.8857\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 847us/step - loss: 0.3253 - accuracy: 0.8896\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8740\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 852us/step - loss: 0.3086 - accuracy: 0.8961\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 769us/step - loss: 0.3037 - accuracy: 0.8935\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.3170 - accuracy: 0.8896\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.9039\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 769us/step - loss: 0.2801 - accuracy: 0.8987\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 796us/step - loss: 0.3094 - accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.3167 - accuracy: 0.8688\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 762us/step - loss: 0.3040 - accuracy: 0.8870\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.3219 - accuracy: 0.8831\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 782us/step - loss: 0.3074 - accuracy: 0.8935\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.2982 - accuracy: 0.8948\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.2824 - accuracy: 0.8935\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.2742 - accuracy: 0.9013\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8779\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8870\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.2959 - accuracy: 0.8909\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.2817 - accuracy: 0.8948\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.2912 - accuracy: 0.8974\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.2582 - accuracy: 0.9130\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.2402 - accuracy: 0.9182\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 964us/step - loss: 0.2536 - accuracy: 0.8922\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.2762 - accuracy: 0.8909\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.2932 - accuracy: 0.8922\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.9052\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.9078\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 973us/step - loss: 0.2649 - accuracy: 0.9000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 973us/step - loss: 0.2751 - accuracy: 0.9013\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 818us/step - loss: 0.2902 - accuracy: 0.8883\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8779\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 957us/step - loss: 0.2696 - accuracy: 0.8909\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.2610 - accuracy: 0.8922\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 964us/step - loss: 0.2538 - accuracy: 0.9117\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9260\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9078\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.2380 - accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.2459 - accuracy: 0.9078\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.9130\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8987\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 964us/step - loss: 0.2921 - accuracy: 0.8922\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.9026\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 973us/step - loss: 0.2499 - accuracy: 0.9117\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 955us/step - loss: 0.2833 - accuracy: 0.8857\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 0s 946us/step - loss: 0.2462 - accuracy: 0.9169\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 0s 970us/step - loss: 0.2343 - accuracy: 0.9130\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.2655 - accuracy: 0.8935\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.2513 - accuracy: 0.9026\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = neural_network()\n",
    "model.fit(X_train, Y_train, batch_size=7, epochs=100, verbose=1)\n",
    " \n",
    "predictions = model.predict_proba(X_test).argmax(axis=1)\n",
    "t = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = np_utils.to_categorical(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      0.96      0.98        25\n",
      "           2       0.90      0.87      0.89        31\n",
      "           3       0.97      1.00      0.99        35\n",
      "           4       0.97      1.00      0.98        28\n",
      "           5       0.92      0.92      0.92        37\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        29\n",
      "           9       1.00      1.00      1.00        27\n",
      "          10       1.00      1.00      1.00        23\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       330\n",
      "   macro avg       0.98      0.98      0.98       330\n",
      "weighted avg       0.98      0.98      0.98       330\n",
      " samples avg       0.98      0.98      0.98       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9757575757575757\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy:{accuracy_score(Y_test, dummy_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 11)                110       \n",
      "=================================================================\n",
      "Total params: 290\n",
      "Trainable params: 290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.151853084564209"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшей работы исходя из результатов выберем модель нейронной сети, которая на 100 данных показывает время работы, выведенное выше. Соберем новые датасеты для последовательностей разных длин: 50, 500, 1000, 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.023246059, 0.005601748, 0.046717988, 0.066559277, 0.857874927],\n",
    "    [0.013646387, 0.049058382, 0.016698736, 0.129693725, 0.79090277],\n",
    "    [0.04620738, 0.001635162, 0.012218447, 0.008067163, 0.931871848],\n",
    "    [0.06745643, 0.118393449, 0.09455569, 0.028992576, 0.690601853],\n",
    "    [0.071950483, 0.2378727, 0.137118006, 0.039143621, 0.513915191]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 1\n",
    "c2 = 2\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.455, 0.545, 0.000, 0.000, 0.000],\n",
    "    [0.223, 0.609, 0.168, 0.000, 0.000],\n",
    "    [0.000, 0.279, 0.429, 0.191, 0.101],\n",
    "    [0.000, 0.000, 0.406, 0.384, 0.210],\n",
    "    [0.000, 0.000, 0.495, 0.315, 0.190]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 51\n",
    "c2 = 102\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.210320514, 0.274879198, 0.119375148, 0.320626736, 0.074798404],\n",
    "    [0.085808181, 0.258198181, 0.331194188, 0.30701685, 0.0177826],\n",
    "    [0.098470341, 0.295037295, 0.159363517, 0.254503354, 0.192625493],\n",
    "    [0.137239473, 0.342470158, 0.308467346, 0.176949439, 0.034873585],\n",
    "    [0.414134897, 0.317554959, 0.061405659, 0.006018718, 0.200885768]\n",
    "])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 202\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.198964414, 0.260941274, 0.062515519, 0.313602016, 0.163976777],\n",
    "    [0.094098288, 0.242054193, 0.319600366, 0.155162279, 0.189084874],\n",
    "    [0.281606257, 0.23585606, 0.001, 0.209688285, 0.271849398],\n",
    "    [0.170857902, 0.140203238, 0.326095823, 0.162519882, 0.200323156],\n",
    "    [0.254473139, 0.120945235, 0.290788292, 0.159027538, 0.174765796]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 302\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.042, 0.958, 0.000, 0.000, 0.000],\n",
    "    [0.144, 0.714, 0.142, 0.000, 0.000],\n",
    "    [0.000, 0.481, 0.166, 0.353, 0.000],\n",
    "    [0.000, 0.000, 0.244, 0.372, 0.384],\n",
    "    [0.628, 0.000, 0.000, 0.035, 0.337]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 402\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.298736925, 0.306256767, 0, 0.264102915, 0.130903393],\n",
    "    [0.34365385, 0.303853456, 0.318253759, 0, 0.034238936],\n",
    "    [0, 0.393997563, 0.023003194, 0.028094888, 0.554904356],\n",
    "    [0, 0.180661219, 0.298764636, 0.2890369, 0.231537245],\n",
    "    [0.11988777, 0.313111886, 0.412344795, 0.154655549, 0]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 502\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0, 0.310635344, 0.369802326, 0.31956233, 0],\n",
    "    [0, 0, 0.275148046, 0.387331667, 0.337520287],\n",
    "    [0.295932886, 0.254979504, 0.44908761, 0, 0],\n",
    "    [0, 0.334192164, 0.027950014, 0, 0.637857822],\n",
    "    [0, 0, 0.366596582, 0.15536363, 0.478039788]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 602\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0, 0.149416596, 0, 0, 0.850583404],\n",
    "    [0.764116183, 0, 0.235883817, 0, 0],\n",
    "    [0.866505491, 0, 0, 0.133494509, 0],\n",
    "    [0, 0.499002278, 0, 0.500997722, 0],\n",
    "    [0, 0, 0.439294583, 0.560705417, 0]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 702\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.420, 0.010, 0.185, 0.150, 0.235],\n",
    "    [0.000, 0.322, 0.138, 0.187, 0.353],\n",
    "    [0.000, 0.000, 0.142, 0.497, 0.361],\n",
    "    [0.000, 0.000, 0.000, 0.857, 0.143],\n",
    "    [0.336, 0.000, 0.000, 0.000, 0.664]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 802\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.468, 0.000, 0.000, 0.000, 0.532],\n",
    "    [0.451, 0.549, 0.000, 0.000, 0.000],\n",
    "    [0.291, 0.209, 0.500, 0.000, 0.000],\n",
    "    [0.032, 0.335, 0.402, 0.231, 0.000],\n",
    "    [0.324, 0.310, 0.170, 0.111, 0.085]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(50, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 902\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([\n",
    "    [0.000, 0.000, 0.178, 0.345, 0.477],\n",
    "    [0.000, 0.000, 0.102, 0.512, 0.386],\n",
    "    [0.000, 0.000, 0.840, 0.057, 0.103],\n",
    "    [0.607, 0.393, 0.000, 0.000, 0.000],\n",
    "    [0.261, 0.739, 0.000, 0.000, 0.000]])\n",
    "list_m = []\n",
    "list_l = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    mc = qe.MarkovChain(matrix)\n",
    "    k = mc.simulate(5000, init=0)\n",
    "    list_l.append(k)\n",
    "    m = transition_matrix(k)\n",
    "    list_m.append(m)\n",
    "    \n",
    "ar = []\n",
    "res = []\n",
    "d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "\n",
    "for el in list_l:\n",
    "    for i in range(1, len(el)):\n",
    "        difference = el[i] - el[i-1]\n",
    "        d[difference] = d[difference] + 1\n",
    "    for val in d.values():\n",
    "        ar.append(val)\n",
    "    res.append(ar)\n",
    "    ar = []\n",
    "    d = {-4:0,-3:0,-2:0,-1:0,0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "c1 = 101\n",
    "c2 = 1002\n",
    "\n",
    "wb = openpyxl.load_workbook('50.xlsx')  \n",
    "ws1 = wb.get_sheet_by_name('Лист1')\n",
    "row = c1  \n",
    "column = 1\n",
    "for ar in list_l:\n",
    "    for el in ar:\n",
    "        ws1.cell(column=column, row=row).value = el\n",
    "        row = row + 1\n",
    "    column = column + 1\n",
    "    row = c1\n",
    "\n",
    "ws2 = wb.get_sheet_by_name('Properties')\n",
    "row = c2  \n",
    "column = 1\n",
    "for ar in res:\n",
    "    for el in ar:\n",
    "        ws2.cell(column=column, row=row).value = el\n",
    "        column = column + 1\n",
    "    row = row + 1\n",
    "    column = 1    \n",
    "\n",
    "save_workbook(wb, '50.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем точность и время построения модели для каждого датасета(меняем параметры в ниже сделанных блоках кода)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>749</td>\n",
       "      <td>468</td>\n",
       "      <td>164</td>\n",
       "      <td>1703</td>\n",
       "      <td>210</td>\n",
       "      <td>581</td>\n",
       "      <td>637</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>777</td>\n",
       "      <td>503</td>\n",
       "      <td>159</td>\n",
       "      <td>1624</td>\n",
       "      <td>185</td>\n",
       "      <td>592</td>\n",
       "      <td>684</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216</td>\n",
       "      <td>771</td>\n",
       "      <td>461</td>\n",
       "      <td>164</td>\n",
       "      <td>1721</td>\n",
       "      <td>211</td>\n",
       "      <td>545</td>\n",
       "      <td>676</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>807</td>\n",
       "      <td>468</td>\n",
       "      <td>143</td>\n",
       "      <td>1693</td>\n",
       "      <td>198</td>\n",
       "      <td>549</td>\n",
       "      <td>702</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>787</td>\n",
       "      <td>486</td>\n",
       "      <td>169</td>\n",
       "      <td>1608</td>\n",
       "      <td>221</td>\n",
       "      <td>598</td>\n",
       "      <td>663</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>219</td>\n",
       "      <td>778</td>\n",
       "      <td>458</td>\n",
       "      <td>150</td>\n",
       "      <td>1720</td>\n",
       "      <td>216</td>\n",
       "      <td>558</td>\n",
       "      <td>652</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>226</td>\n",
       "      <td>762</td>\n",
       "      <td>513</td>\n",
       "      <td>121</td>\n",
       "      <td>1673</td>\n",
       "      <td>195</td>\n",
       "      <td>619</td>\n",
       "      <td>656</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>213</td>\n",
       "      <td>787</td>\n",
       "      <td>480</td>\n",
       "      <td>168</td>\n",
       "      <td>1628</td>\n",
       "      <td>230</td>\n",
       "      <td>584</td>\n",
       "      <td>689</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>232</td>\n",
       "      <td>751</td>\n",
       "      <td>480</td>\n",
       "      <td>150</td>\n",
       "      <td>1715</td>\n",
       "      <td>192</td>\n",
       "      <td>578</td>\n",
       "      <td>657</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>252</td>\n",
       "      <td>753</td>\n",
       "      <td>477</td>\n",
       "      <td>160</td>\n",
       "      <td>1671</td>\n",
       "      <td>198</td>\n",
       "      <td>556</td>\n",
       "      <td>653</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    -4   -3   -2   -1     0    1    2    3    4  target\n",
       "0  235  749  468  164  1703  210  581  637  252       0\n",
       "1  228  777  503  159  1624  185  592  684  247       0\n",
       "2  216  771  461  164  1721  211  545  676  234       0\n",
       "3  207  807  468  143  1693  198  549  702  232       0\n",
       "4  221  787  486  169  1608  221  598  663  246       0\n",
       "5  219  778  458  150  1720  216  558  652  248       0\n",
       "6  226  762  513  121  1673  195  619  656  234       0\n",
       "7  213  787  480  168  1628  230  584  689  220       0\n",
       "8  232  751  480  150  1715  192  578  657  244       0\n",
       "9  252  753  477  160  1671  198  556  653  279       0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"5000.xlsx\", \"Properties\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1)\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(9))\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.590694</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.129440</td>\n",
       "      <td>0.468628</td>\n",
       "      <td>0.140093</td>\n",
       "      <td>0.666284</td>\n",
       "      <td>0.869031</td>\n",
       "      <td>0.227848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350769</td>\n",
       "      <td>0.612776</td>\n",
       "      <td>0.291088</td>\n",
       "      <td>0.125493</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>0.123416</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.933151</td>\n",
       "      <td>0.223327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.332308</td>\n",
       "      <td>0.608044</td>\n",
       "      <td>0.266782</td>\n",
       "      <td>0.129440</td>\n",
       "      <td>0.474032</td>\n",
       "      <td>0.140761</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.922237</td>\n",
       "      <td>0.211573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.318462</td>\n",
       "      <td>0.636435</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.112865</td>\n",
       "      <td>0.465626</td>\n",
       "      <td>0.132088</td>\n",
       "      <td>0.629587</td>\n",
       "      <td>0.957708</td>\n",
       "      <td>0.209765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.620662</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.133386</td>\n",
       "      <td>0.440108</td>\n",
       "      <td>0.147432</td>\n",
       "      <td>0.685780</td>\n",
       "      <td>0.904502</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.356923</td>\n",
       "      <td>0.910883</td>\n",
       "      <td>0.210648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332333</td>\n",
       "      <td>0.129420</td>\n",
       "      <td>0.948394</td>\n",
       "      <td>0.869031</td>\n",
       "      <td>0.308318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.183449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326629</td>\n",
       "      <td>0.112075</td>\n",
       "      <td>0.924312</td>\n",
       "      <td>0.875853</td>\n",
       "      <td>0.348101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0.363077</td>\n",
       "      <td>0.947161</td>\n",
       "      <td>0.195602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.118746</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.874488</td>\n",
       "      <td>0.339060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.953470</td>\n",
       "      <td>0.214120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306214</td>\n",
       "      <td>0.136758</td>\n",
       "      <td>0.916284</td>\n",
       "      <td>0.916780</td>\n",
       "      <td>0.325497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.940852</td>\n",
       "      <td>0.195023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313419</td>\n",
       "      <td>0.136758</td>\n",
       "      <td>0.910550</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.358047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            -4        -3        -2        -1         0         1         2  \\\n",
       "0     0.361538  0.590694  0.270833  0.129440  0.468628  0.140093  0.666284   \n",
       "1     0.350769  0.612776  0.291088  0.125493  0.444911  0.123416  0.678899   \n",
       "2     0.332308  0.608044  0.266782  0.129440  0.474032  0.140761  0.625000   \n",
       "3     0.318462  0.636435  0.270833  0.112865  0.465626  0.132088  0.629587   \n",
       "4     0.340000  0.620662  0.281250  0.133386  0.440108  0.147432  0.685780   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1095  0.356923  0.910883  0.210648  0.000000  0.332333  0.129420  0.948394   \n",
       "1096  0.392308  0.943218  0.183449  0.000000  0.326629  0.112075  0.924312   \n",
       "1097  0.363077  0.947161  0.195602  0.000000  0.323026  0.118746  0.931193   \n",
       "1098  0.341538  0.953470  0.214120  0.000000  0.306214  0.136758  0.916284   \n",
       "1099  0.392308  0.940852  0.195023  0.000000  0.313419  0.136758  0.910550   \n",
       "\n",
       "             3         4  \n",
       "0     0.869031  0.227848  \n",
       "1     0.933151  0.223327  \n",
       "2     0.922237  0.211573  \n",
       "3     0.957708  0.209765  \n",
       "4     0.904502  0.222423  \n",
       "...        ...       ...  \n",
       "1095  0.869031  0.308318  \n",
       "1096  0.875853  0.348101  \n",
       "1097  0.874488  0.339060  \n",
       "1098  0.916780  0.325497  \n",
       "1099  0.863574  0.358047  \n",
       "\n",
       "[1100 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_of_values = {}\n",
    "count = len(X.columns.tolist())\n",
    "\n",
    "for i in range(0, count):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(np.array(X.iloc[:,i]).reshape(-1, 1))\n",
    "    scaled_data = scaled_data.reshape(len(scaled_data))\n",
    "    d_of_values[data.columns.tolist()[i]] = scaled_data\n",
    "    \n",
    "x = pd.DataFrame(d_of_values)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, dummy_y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 0s 791us/step - loss: 2.3925 - accuracy: 0.0701\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 0s 780us/step - loss: 2.3153 - accuracy: 0.1299\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 2.1879 - accuracy: 0.2221\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 0s 818us/step - loss: 2.0173 - accuracy: 0.2636\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 1.8406 - accuracy: 0.3104\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 0s 870us/step - loss: 1.7001 - accuracy: 0.3701\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 1.5893 - accuracy: 0.4558\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 0s 846us/step - loss: 1.4629 - accuracy: 0.5299\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 0s 770us/step - loss: 1.3542 - accuracy: 0.5844\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 0s 764us/step - loss: 1.2682 - accuracy: 0.6377\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 0s 803us/step - loss: 1.2087 - accuracy: 0.6714\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 0s 785us/step - loss: 1.1324 - accuracy: 0.7052\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 1.0174 - accuracy: 0.7364\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.9730 - accuracy: 0.7026\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 0s 785us/step - loss: 0.8881 - accuracy: 0.7195\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 0s 809us/step - loss: 0.8246 - accuracy: 0.7494\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 0s 818us/step - loss: 0.8077 - accuracy: 0.7455\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 0s 804us/step - loss: 0.7765 - accuracy: 0.7870\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 0s 872us/step - loss: 0.7083 - accuracy: 0.7844\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.7195 - accuracy: 0.7948\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.7058 - accuracy: 0.7818\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.6874 - accuracy: 0.7766\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.6574 - accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.7948\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.80 - 0s 846us/step - loss: 0.6556 - accuracy: 0.7896\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.6452 - accuracy: 0.7961\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 0s 827us/step - loss: 0.6000 - accuracy: 0.7935\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.8052\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 0s 982us/step - loss: 0.6182 - accuracy: 0.8039\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 0s 909us/step - loss: 0.5691 - accuracy: 0.8390\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 0s 982us/step - loss: 0.5420 - accuracy: 0.8195\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.8299\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8506\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.8260\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 0s 973us/step - loss: 0.5893 - accuracy: 0.8195\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 0s 973us/step - loss: 0.5601 - accuracy: 0.8065\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 0s 918us/step - loss: 0.5099 - accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 0s 822us/step - loss: 0.5048 - accuracy: 0.8532\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.5286 - accuracy: 0.8364\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.4833 - accuracy: 0.8545\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 0s 954us/step - loss: 0.4855 - accuracy: 0.8455\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.4815 - accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.8649\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.4564 - accuracy: 0.8558\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 0s 788us/step - loss: 0.4531 - accuracy: 0.8532\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.4818 - accuracy: 0.8403\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.4804 - accuracy: 0.8390\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 0s 939us/step - loss: 0.4425 - accuracy: 0.8545\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 0s 816us/step - loss: 0.4482 - accuracy: 0.8481\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 0s 873us/step - loss: 0.4463 - accuracy: 0.8377\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.8584\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8532\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 0s 882us/step - loss: 0.4070 - accuracy: 0.8701\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 0s 818us/step - loss: 0.4089 - accuracy: 0.8896\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 0s 771us/step - loss: 0.4271 - accuracy: 0.8532\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 0s 845us/step - loss: 0.3898 - accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.4614 - accuracy: 0.8416\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 0s 800us/step - loss: 0.3929 - accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 0s 836us/step - loss: 0.3989 - accuracy: 0.8714\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8740\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8584\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8597\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8610\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8701\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8688\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 0s 927us/step - loss: 0.3908 - accuracy: 0.8636\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 0s 982us/step - loss: 0.4078 - accuracy: 0.8753\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8610\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8740\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 0s 809us/step - loss: 0.3731 - accuracy: 0.8753\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.3773 - accuracy: 0.8688\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 0s 898us/step - loss: 0.3307 - accuracy: 0.8857\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 0s 964us/step - loss: 0.3616 - accuracy: 0.8701\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8753\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8675\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8753\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 0s 891us/step - loss: 0.3548 - accuracy: 0.8792\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 0s 991us/step - loss: 0.3571 - accuracy: 0.8792\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8701\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 0s 936us/step - loss: 0.3965 - accuracy: 0.8766\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 0s 864us/step - loss: 0.3570 - accuracy: 0.8922\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 0s 800us/step - loss: 0.3777 - accuracy: 0.8753\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 0s 830us/step - loss: 0.3843 - accuracy: 0.8675\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 0s 824us/step - loss: 0.3530 - accuracy: 0.8831\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 0s 936us/step - loss: 0.3279 - accuracy: 0.8935\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 0s 855us/step - loss: 0.3670 - accuracy: 0.8857\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 0s 791us/step - loss: 0.3131 - accuracy: 0.9065\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.3814 - accuracy: 0.8727\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 0s 900us/step - loss: 0.3338 - accuracy: 0.8974\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 0s 918us/step - loss: 0.3717 - accuracy: 0.8948\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 0s 828us/step - loss: 0.3728 - accuracy: 0.8844\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8987\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 0s 782us/step - loss: 0.3175 - accuracy: 0.8987\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 0s 761us/step - loss: 0.3113 - accuracy: 0.9052\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 0s 955us/step - loss: 0.3643 - accuracy: 0.89480s - loss: 0.3780 - accuracy: 0.\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 0s 879us/step - loss: 0.3563 - accuracy: 0.8987\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 0s 791us/step - loss: 0.3236 - accuracy: 0.8987\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 0s 800us/step - loss: 0.3088 - accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = neural_network()\n",
    "model.fit(X_train, Y_train, batch_size=7, epochs=100, verbose=1)\n",
    " \n",
    "predictions = model.predict_proba(X_test).argmax(axis=1)\n",
    "t = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = np_utils.to_categorical(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy:{accuracy_score(Y_test, dummy_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.426212549209595"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Замер времени работы нейронной сети и точности построения в зависимости от длины последовательностей:\n",
    "50 - время 10.685662031173706, Accuracy: 0.8566666666666667  \n",
    "100 - время 11.151853084564209, Accuracy:0.9757575757575757  \n",
    "500 - время 11.178090810775757, Accuracy:0.990909090909091  \n",
    "1000 - время 11.186399221420288, Accuracy:0.9969696969696976  \n",
    "5000 - время 11.426212549209595, Accuracy: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([50,100,500,1000,5000],[10.685662031173706,11.151853084564209,11.178090810775757,11.186399221420288,11.426212549209595])  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод  \n",
    "\n",
    "Таким образом, сразу несколько моделей многоклассовой классификации показали хороший результат. Была построена модель нейронной сети для для разных датасетов, посчитанных в зависимости от длин последовательностей. Посчитанная метрика accuracy, время работы модели и построенный график, что время работы модели зависит прямо пропорционально от длин последовательностей, а accuracy увеличивается с ростом длины последовательности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
